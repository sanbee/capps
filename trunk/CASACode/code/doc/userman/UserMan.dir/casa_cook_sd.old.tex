%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% STM 2007-04-13  split from previous version

%\chapter{Single Dish Data Processing}
\chapter[Appendix: Single Dish Data Processing]{Single Dish Data Processing}
\label{chapter:sd}

%Version  JM 2007-03-05
%Updated STM 2007-03-07
%Updated STM 2007-04-15
%Updated STM 2007-10-10  beta release (spell-checked)
%Updated STM 2007-11-22  put in appendix for beta release 0.0

{\bf BETA ALERT:} The single-dish analysis package within CASA
is still largely toolkit-based, with a few experimental basic
tasks thrown in.  It is included in the Beta release for the use
of the ALMA computing and commissioning groups, and is not intended
for general users.  Therefore, this is included in this Cookbook
as an appendix.

For single-dish spectral calibration and analysis, 
CASA uses the ATNF Spectral Analysis Package (ASAP).  This is
imported as the {\tt sd} tool, and forms the basis for a series
of tasks (the ``SDtasks'') that encapsulate the functionality
within the standard CASA task framework.  ASAP was developed to
support the Australian telescopes such as Mopra, Parkes, and
Tidbinbilla, and we have adapted it for use within CASA for
GBT and eventually ALMA data also.  For details on ASAP, see
the ASAP home page at ATNF: 
\begin{itemize}
   \item \url{http://www.atnf.csiro.au/computing/software/asap/}
\end{itemize}
You can also download the ASAP User Guide and Reference Manual at this
web site.  There is also a brief tutorial.  Note that within CASA,
the ASAP tools are prefaced with {\tt sd.}, e.g. where it
says in the ASAP User Guide to use {\tt scantable} you will use
{\tt sd.scantable} in CASA.  See \S~\ref{section:sd.asap} for more
information on the tools.

All of the ASAP functionality is available with a CASA
installation.  In the following, we outline how to access ASAP
functionality within CASA with the tasks and tools,
and the data flow for standard use cases.

If you run into trouble, be sure to check the list of known issues
and features of ASAP and the SDtasks presented in 
\S~\ref{section:sd.issues} first.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Guidelines for Use of ASAP and SDtasks in CASA}
\label{section:sd.intro}

\subsection{Environment Variables}
\label{section:sd.intro.env}

There are a number of environment variables that the ASAP tools
(and thus the SDtasks) use to help control their operation.
These are described in the ASAP User Guide as being in the 
{\tt .asaprc} file.  Within CASA, these are contained in the
Python dictionary {\tt sd.rcParams} and are accessible through
its keys and values.  For SDtask users, the most important are the
{\tt verbose} parameter controlling the display of detailed
messages from the tools. By default 
\small
\begin{verbatim}
     sd.rcParams['verbose'] = True
\end{verbatim}
\normalsize
and you get lots of messages.  Also
), and the {\tt scantable.storage}
parameter controlling whether scantable operations are done
in memory or on disk.  The default 
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'memory'
\end{verbatim}
\normalsize
does it in memory (best choice if you have enough), while to
force the scantables to disk use
\small
\begin{verbatim}
     sd.rcParams['scantable.storage'] = 'disk'
\end{verbatim}
\normalsize
which might be necessary to allow processing of large datasets.
See \S~\ref{subsection:sd.asap.environ} for more details on the
ASAP environment variables.

\subsection{Assignment}
\label{section:sd.intro.ass}

Some ASAP methods and function require you to assign that method
to a variable which you can then manipulate.  This includes
{\tt sd.scantable} and {\tt sd.selector}, which make objects.
For example,
\small
\begin{verbatim}
     s = sd.scantable('OrionS_rawACSmod', average=False)
\end{verbatim}
\normalsize

\subsection{Lists}
\label{section:sd.intro.lists}

For lists of scans or IFs, such as in {\tt scanlist} and {\tt
iflist} in the SDtasks, the tasks and functions want a comma-separated 
Python list, e.g.
\small
\begin{verbatim}
     scanlist = [241, 242, 243, 244, 245, 246]
\end{verbatim}
\normalsize
You can use the Python {\tt range} function to generate a list of
consecutive numbers, e.g.
\small
\begin{verbatim}
     scanlist = range(241,247)
\end{verbatim}
\normalsize
giving the same list as above, e.g.
\small
\begin{verbatim}
CASA <3>: scanlist=range(241,247)
CASA <4>: print scanlist
[241, 242, 243, 244, 245, 246]
\end{verbatim}
\normalsize
You can also combine multiple ranges by summing lists
\small
\begin{verbatim}
CASA <5>: scanlist=range(241,247) + range(251,255)
CASA <6>: print scanlist
[241, 242, 243, 244, 245, 246, 251, 252, 253, 254]
\end{verbatim}
\normalsize
Note that in the future, the {\tt sd} tools and SDtasks will use
the same selection language as in the synthesis part of the package.

Spectral regions, such as those for setting masks, are pairs of
min and max values for whatever spectral axis unit is currently
chosen.  These are fed into the tasks and tools as a list of lists,
with each list element a list with the {\tt [min,max]} for that
sub-region, e.g.
\small
\begin{verbatim}
     masklist=[[1000,3000], [5000,7000]].
\end{verbatim}
\normalsize

\subsection{Dictionaries}
\label{section:sd.intro.dict}

Currently, the SDtasks use the Python dictionary {\tt xstat} as
a return variable for the results of line fitting (in {\tt sdfit})
and region statistics (in {\tt sdstat}).  You can then access the
elements of these through the keywords, e.g.
\small
\begin{verbatim}
CASA <10>: sdstat()
Current fluxunit = K
No need to convert fluxunits
Using current frequency frame
Using current doppler convention

CASA <11>: xstat
  Out[11]: 
{'eqw': 70.861755476162784,
 'max': 1.2750182151794434,
 'mean': 0.35996028780937195,
 'median': 0.23074722290039062,
 'min': -0.20840644836425781,
 'rms': 0.53090775012969971,
 'stddev': 0.39102539420127869,
 'sum': 90.350028991699219}
\end{verbatim}
\normalsize
You can then use these values in scripts by accessing this dictionary,
e.g.
\small
\begin{verbatim}
CASA <12>: line_stat = xstat

CASA <13>: print "Line max = %5.3f K" % (line_stat['max'])
Line max = 1.275 K
\end{verbatim}
\normalsize
for example.

\subsection{Line Formatting}
\label{section:sd.intro.line}

The SDtasks trap leading and trailing whitespace on string parameters
(such as {\tt infile} and {\tt sdfile}), but ASAP does not, so be
careful with setting string parameters.  ASAP is also case-sensitive,
with most parameters being upper-case, such as {\tt ASAP} for the
{\tt sd.scantable.save} file format.  The SDtasks are generally
more forgiving.

Also, beware Python's sensitivity to indenting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Single Dish Analysis Tasks}
\label{section:sd.sdtasks}

A set of single dish tasks is available for simplifying basic
reduction activities. Currently the list includes:

\begin{itemize}

\item {\bf sdcal} --- select, calibrate, average, smooth, and 
fit/remove spectral baselines from SD data

\item {\bf sdfit} --- line fitting to SD spectra

\item {\bf sdlist} --- print a summary of a SD dataset

\item {\bf sdplot} --- plotting of SD spectra, including overlay of line
catalog data

\item {\bf sdstat} --- compute statistics of regions of SD spectra

\end{itemize}

All of the SDtasks work from a file on disk rather than from
a scantable in memory as the ASAP toolkit does (see 
\S~\ref{section:sd.asap}.  Inside the tasks we invoke a call
to {\tt sd.scantable} to read in the data.  The scantable objects
do not persist within CASA after completion of the tasks, and
are destroyed to free up memory.

The task {\tt sdcal} is the workhorse for the calibration, selection,
averaging, baseline fitting, smoothing, and writing of datasets.  It
is the only SDtask that can write out a dataset.  Its operation is
controlled by three main "mode" parameters: {\tt calmode} (which selects
the type of calibration, if any, to be applied), {\tt kernel} (which selects
the smoothing), and {\tt blmode} (which selects baseline fitting).  There
are also parameters controlling the selection such as {\tt scanlist}, 
{\tt iflist}, {\tt field}, {\tt scanaverage}, {\tt timeaverage}, and
{\tt polaverage}.  Note that {\tt sdcal} can be
run with {\tt calmode='none'} to allow re-selection or writing out of data
that is already calibrated.

There is a "wiring diagram" of the dataflow and control inputs for
{\tt sdcal} shown in Figure~\ref{fig:sdcal}.  This might help 
you chart your course through the calibration.

\begin{figure}[h!]
\pnghigh{sdcal_wiring_diagram}{8.5}
\caption{\label{fig:sdcal} Wiring diagram for the SDtask {\tt sdcal}.
The stages of processing within the task are shown, along with the
parameters that control them. }
\hrulefill
\end{figure}

The SDtasks support the import and export file formats supported
by ASAP itself.  For import, this includes:  ASAP (scantables), 
MS (CASA measurement set), RPFITS and SDFITS.  For export, this
includes: ASAP (scantables), MS (CASA measurement set),
ASCII (text file), SDFITS (a flavor of SD FITS).

You can get a brief summary of the data in a file using the {\tt sdlist}
task.

Plotting of spectra is handled in the {\tt sdplot} task.  It also offers
some selection, averaging and smoothing options in case you are
working from a dataset that has not been split or averaged.  Note that
there is some rudimentary plotting capability in the {\tt sdcal} and
{\tt sdfit} tasks, controlled through the {\tt plotlevel} parameter, 
to aid in the assessment of the performance of these tasks.

Basic statistics on spectral regions is available in the {\tt sdstat} task.
Results are passed in a Python dictionary return variable {\tt xstat}.

Basic Gaussian line-fitting is handled by the {\tt sdfit} task.  It can deal
with the simpler cases, and offers some automation, but more complicated
fitting is best accomplished through the toolkit ({\tt sd.fitter}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{SDtask Summaries}
\label{section:sd.sdtasks.tasks}

The following are the list of parameters and
brief descriptions of each of the SDtasks.
These descriptions are also contained in the information produced
by {\tt help <taskname>}, once {\tt asap\_init} has been invoked.
Note that you can use {\tt inp <taskname>} on these as for other tasks.

\begin{itemize}
\item {\bf sdcal}

\begin{verbatim}
    Keyword arguments:
    infile -- name of input SD dataset
            options: (str) file name
            default: '' (none set) REQUIRED
            example: 'mopra-2005-05-08_0350.rpf'
                     Supported formats: ASAP,MS,RPFITS,SDFITS
    telescope -- the telescope name or characteristics
            options: (str) name or (list) list of gain info
            default: '' (none set)
            example: telescope='GBT' for the GBT
                     telescope='AT' for one of the default scopes
                     known to ASAP.
                     telescope=[104.9,0.43] diameter(m), ap.eff.
                     telescope=[0.743] gain in Jy/K
                     telescope='FIX' to change default fluxunit
                     see description below
    fluxunit -- units for line flux
            options: 'K','Jy',''
            default: '' (keep current fluxunit)
            WARNING: For GBT data, see description below.
    specunit -- units for spectral axis
            options: (str) 'channel','km/s','GHz','MHz','kHz','Hz'
            default: 'channel'
            example: this will be the units for masklist
    frame -- frequency frame for spectral axis
            options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                     'GEO','GALACTO','LGROUP','CMB'
            default: currently set frame in scantable
            WARNING: frame='REST' not yet implemented
    doppler -- doppler mode
            options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
            default: currently set doppler in scantable
    calmode -- calibration mode
            options: 'ps','nod','fs','fsotf','quotient','none'
            default: 'none'
            example: choose mode 'none' if you have
                     already calibrated and want to
                     try baselines or averaging
    scanlist -- list of scan numbers to process
            default: [] (use all scans)
            example: [21,22,23,24]
                     this selection is in addition to field
                     and iflist
    field -- selection string for selecting scans by name
            default: '' (no name selection)
            example: 'FLS3a*'
                     this selection is in addition to scanlist
                     and iflist
    iflist -- list of IF id numbers to select
            default: [] (use all IFs)
            example: [15]
                     this selection is in addition to scanlist
                     and field
    scanaverage -- average integrations within scans
            options: (bool) True,False
            default: False
            example: if True, this happens in read-in
                     For GBT, set False!
    timeaverage -- average times for multiple scan cycles
            options: (bool) True,False
            default: False
            example: if True, this happens after calibration
    polaverage -- average polarizations
            options: (bool) True,False
            default: False
    kernel -- type of spectral smoothing
            options: 'hanning','gaussian','boxcar','none'
            default: 'none'
    kwidth -- width of spectral smoothing kernel
            options: (int) in channels 
            default: 5
            example: 5 or 10 seem to be popular for boxcar
                     ignored for hanning (fixed at 5 chans)
                     (0 will turn off gaussian or boxcar)
    tau -- atmospheric optical depth
            default: 0.0 (no correction)
    blmode -- mode for baseline fitting
            options: (str) 'auto','list','none'
            default: 'none'
            example: blmode='none' turns off baseline fitting
                     blmode='auto' uses AUTOPARS (see below)
                     in addition to blpoly to run linefinder
                     to determine line-free regions
                     USE WITH CARE! May need to tweak AUTOPARS.
    blpoly -- order of baseline polynomial
            options: (int) (<0 turns off baseline fitting)
            default: 5
            example: typically in range 2-9 (higher values
                     seem to be needed for GBT)
    interactive -- interactive mode for baseline fitting
            options: (bool) True,False
            default: False
            WARNING: Currently this just asks whether you accept
                     the displayed fit and if not, continues
                     without doing any baseline fit.
    masklist -- list of mask regions to INCLUDE in BASELINE fit
            default: [] (entire spectrum)
            example: [[1000,3000],[5000,7000]]
                     if blmode='auto' then this mask will be applied
                     before fitting
    sdfile -- Name of output file
            default: '' (<infile>_cal)
            example: note that sdfile is the OUTPUT of sdcal and
                     is the INPUT filename param for the other
                     sdtasks to steamline processing
            WARNING: output file will be overwritten
    outform -- format of output file
            options: 'ASCII','SDFITS','MS','ASAP'
            default: 'ASAP'
            example: the ASAP format is easiest for further sd
                     processing; use MS for CASA imaging.
                     If ASCII, then will append some stuff to
                     the sdfile name
    plotlevel -- control for plotting of results
            options: (int) 0=none, 1=some, 2=more, <0=hardcopy
            default: 0 (no plotting)
            example: plotlevel<0 as abs(plotlevel), e.g.
                     -1 => hardcopy of final plot (will be named
                     <sdfile>_calspec.eps)
            WARNING: be careful plotting in fsotf mode!
    
    AUTOPARS: the following parameters are used for blmode='auto' ONLY
    -------------------------------------------------------------------
    thresh -- S/N threshold for linefinder
            default: 5
            example: a single channel S/N ratio above which the channel is
                     considered to be a detection
    avg_limit -- channel averaging for broad lines
            default: 4
            example: a number of consequtive channels not greater than
                     this parameter can be averaged to search for broad lines
    edge -- channels to drop at beginning and end of spectrum
            default: 0
            example: [1000] drops 1000 channels at beginning AND end
                     [1000,500] drops 1000 from beginning and 500 from end
    
            Note: For bad baselines threshold should be increased,
            and avg_limit decreased (or even switched off completely by
            setting this parameter to 1) to avoid detecting baseline
            undulations instead of real lines.
\end{verbatim}
    
    DESCRIPTION:
    
    Task {\tt sdcal} performs data selection, calibration, and/or spectral
    baseline fitting for single-dish spectra.  By setting {\tt calmode='none'}
    one can run {\tt sdcal} on already calibrated data, for further selection
    or baseline fitting.  Likewise, one can set {\tt blmode='none'} to bypass
    baseline fitting.
    
    If you give multiple IFs in {\tt iflist}, then your scantable will have
    multiple IFs.  This can be handled, but there can be funny interactions
    later on.  We recommend you split each IF out into separate files
    by re-running {\tt sdcal} with each IF in turn.
    
    ASAP recognizes the data of the "AT" telescopes, but currently
    does not know about the GBT or any other telescope. This task
    does know about GBT.  Therefore, if you wish to change the
    {\tt fluxunit} (see below), then you need to tell it what to do.  If
    you set {\tt telescope = 'AT'} it will use its internal defaults.  If
    you set {\tt telescope = 'GBT'}, it will use an approximate aperture
    efficiency conversion.  If you give it a list instead of a
    string, then if the list has a single float it is assumed to
    be the gain in Jy/K, if two or more elements they are assumed
    to be telescope diameter (m) and aperture efficiency
    respectively.
    
    Note that {\tt sdcal} assumes that the {\tt fluxunit} is set correctly in
    the data already.  If not, then set {\tt telescope = 'FIX'} and it
    will set the default units to fluxunit without conversion.
    WARNING: If the data in {\tt infile} is an ms from GBT, it will
    currently say its in {\tt 'Jy'} but it is really {\tt 'K'}, so set
    {\tt telescope = 'FIX'} and {\tt fluxunit='K'} to fix this.
	
\item {\bf sdfit}

\begin{verbatim}
    Keyword arguments:
    sdfile -- name of input SD dataset
            default: none - must input file name
            example: 'mysd.asap'
                     See sdcal for allowed formats.
    telescope -- the telescope name or characteristics
            options: (str) name or (list) list of gain info
            default: '' (none set)
            example: telescope='GBT' for the GBT
                     telescope='AT' for one of the default scopes
                     known to ASAP.
                     telescope=[104.9,0.43] diameter(m), ap.eff.
                     telescope=[0.743] gain in Jy/K
                     telescope='FIX' to change default fluxunit
                     see description below
    fluxunit -- units for line flux
            options: (str) 'K','Jy',''
            default: '' (keep current fluxunit)
            WARNING: For GBT data, see description below.
    specunit -- units for spectral axis
            options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
            default: '' (keep current specunit)
    frame -- frequency frame for spectral axis
            options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                     'GEO','GALACTO','LGROUP','CMB'
            default: currently set frame in scantable
            WARNING: frame='REST' not yet implemented
    doppler -- doppler mode
            options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
            default: currently set doppler in scantable
    scanlist -- list of scan numbers to process
            default: [] (use all scans)
            example: [21,22,23,24]
    field -- selection string for selecting scans by name
            default: '' (no name selection)
            example: 'FLS3a*'
                     this selection is in addition to scanlist
                     and iflist
    iflist -- list of IF id numbers to select
            default: [] (use all IFs)
            example: [15]
    fitmode -- mode for fitting
            options: (str) 'list','auto'
            default: 'auto'
            example: 'list' will use maskline to define regions to
                            fit for lines with nfit in each
                     'auto' will use the linefinder to fit for lines
                            using autopars (see below)
    maskline -- list of mask regions to INCLUDE in LINE fitting
            default: all
            example: maskline=[[3900,4300]] for a single region, or
                     maskline=[[3900,4300],[5000,5400]] for two, etc.
    invertmask -- invert mask (EXCLUDE masklist instead)
            options: (bool) True, False
            default: False
            example: invertmask=True, then will make one region that is
                     the exclusion of the maskline regions
    nfit -- list of number of gaussian lines to fit in in maskline region
            default: 0 (no fitting)
            example: nfit=[1] for single line in single region,
                     nfit=[2] for two lines in single region,
                     nfit=[1,1] for single lines in each of two regions, etc.
    fitfile -- name of output file for fit results
            default: no output fit file
            example: 'mysd.fit'
    plotlevel -- control for plotting of results
            options: (int) 0=none, 1=some, 2=more
            default: 0 (no plotting)
            example: plotlevel=1 plots fit and residual
                     no hardcopy available for fitter
            WARNING: be careful plotting OTF data with lots of fields
    
    AUTOPARS: the following parameters are used for fitmode='auto' ONLY
    -------------------------------------------------------------------
    thresh -- S/N threshold for linefinder
            default: 5
            example: a single channel S/N ratio above which the channel is
                     considered to be a detection
    min_nchan -- minimum number of consecutive channels for linefinder
            default: 3
            example: minimum number of consecutive channels required to pass threshold
    avg_limit -- channel averaging for broad lines
            default: 4
            example: a number of consequtive channels not greater than
                     this parameter can be averaged to search for broad lines
    box_size -- running mean box size
            default: 0.2
            example: a running mean box size specified as a fraction
                     of the total spectrum length
    edge -- channels to drop at beginning and end of spectrum
            default: 0
            example: [1000] drops 1000 channels at beginning AND end
                     [1000,500] drops 1000 from beginning and 500 from end
    
            Note: For bad baselines threshold should be increased,
            and avg_limit decreased (or even switched off completely by
            setting this parameter to 1) to avoid detecting baseline
            undulations instead of real lines.
    
    -------------------------------------------------------------------
    xstat -- RETURN ONLY: a Python dictionary of line statistics
            keys:    'peak','cent','fwhm'
            example: each value is a list of lists with one list of
                     2 entries [fitvalue,error] per component.
                     e.g. xstat['peak']=[[234.9, 4.8],[234.2, 5.3]]
                     for 2 components.
\end{verbatim}
    
    DESCRIPTION:
    
    Task {\tt sdfit} is a basic line-fitter for single-dish spectra.
    It assumes that the spectra have been calibrated in {\tt sdcal}.
    Furthermore, it assumes that any selection of scans, IFs,
    polarizations, and time and channel averaging/smoothing has
    also already been done (in {\tt sdcal}) as there are no controls
    for these.  Note that you can run {\tt sdcal} with {\tt calmode 
    = 'none'} and do selection, writing out a new scantable.
    
    Note that multiple scans and IFs can in principle be handled, but
    we recommend that you use {\tt scanlist}, {\tt field}, and 
    {\tt iflist} to give a single selection for each fit.
    
    For complicated spectra, {\tt sdfit} does not do a good job of
    "auto-guessing" the starting model for the fit.  We recommend
    you use {\tt sd.fitter} in the toolkit which has more options, such
    as fixing components in the fit and supplying starting guesses
    by hand.
    
    WARNING: {\tt sdfit} will currently return the fit for the first
    row in the scantable.  Does not handle multiple polarizations.
    
    See the {\tt sdcal} description for information on {\tt fluxunit} 
    conversion and the {\tt telescope} parameter.

\item {\bf sdlist}

\begin{verbatim}
    Keyword arguments:
    infile -- name of input SD dataset
    scanaverage -- average integrations within scans
            options: (bool) True,False
            default: False
            example: if True, this happens in read-in
                     For GBT, set False!
    listfile -- Name of output file for summary list
            default: '' (no output file)
            example: 'mysd_summary.txt'
            WARNING: output file will be overwritten
\end{verbatim}
    
    DESCRIPTION:
    
    Task {\tt sdlist} lists the scan summary of the dataset after importing
    as a scantable into ASAP.  It will optionally output this summary
    as file.
    
    Note that if your {\tt PAGER} environment variable is set to 'less' and
    you have set the {\tt 'verbose'} ASAP environment variable to True
    (the default), then the screen version of the summary will page.
    You can disable this for sdlist by setting
         {\tt sd.rcParams['verbose']=False}
    before running {\tt sdlist}.  Set it back afterward if you want lots
    of information.

\item {\bf sdplot}

\begin{verbatim}
    Keyword arguments:
    sdfile -- name of input SD dataset
            default: none - must input file name
            example: 'mysd.asap'
                     See sdcal for allowed formats.
    telescope -- the telescope name or characteristics
            options: (str) name or (list) list of gain info
            default: '' (none set)
            example: telescope='GBT' for the GBT
                     telescope='AT' for one of the default scopes
                     known to ASAP.
                     telescope=[104.9,0.43] diameter(m), ap.eff.
                     telescope=[0.743] gain in Jy/K
                     telescope='FIX' to change default fluxunit
                     see description below
    fluxunit -- units for line flux
            options: 'K','Jy',''
            default: '' (keep current unit)
            WARNING: For GBT data, see description below.
    specunit -- units for spectral axis
            options: (str) 'channel','km/s','GHz','MHz','kHz','Hz',''
            default: '' (keep current specunit)
            example: this will be the units for masklist
    frame -- frequency frame for spectral axis
            options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                     'GEO','GALACTO','LGROUP','CMB'
            default: currently set frame in scantable
            WARNING: frame='REST' not yet implemented
    doppler -- doppler mode
            options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
            default: currently set doppler in scantable
    scanlist -- list of scan numbers to process
            default: [] (use all scans)
            example: [21,22,23,24]
    field -- selection string for selecting scans by name
            default: '' (no name selection)
            example: 'FLS3a*'
                     this selection is in addition to scanlist
                     and iflist
    iflist -- list of IF id numbers to select
            default: [] (use all IFs)
            example: [15]
    scanaverage -- average integrations within scans
            options: (bool) True,False
            default: False
            example: if True, this happens in read-in
    timeaverage -- average times for multiple scans
            options: (bool) True,False
            default: True
    polaverage -- average polarizations
            options: (bool) True,False
            default: True
    kernel -- type of spectral smoothing
            options: 'hanning','gaussian','boxcar','none'
            default: 'none'
    kwidth -- width of spectral smoothing kernel
            options: (int) in channels 
            default: 5
            example: 5 or 10 seem to be popular for boxcar
                     ignored for hanning (fixed at 5 chans)
                     (0 will turn off gaussian or boxcar)
    stack -- code for stacking on single plot
            options: 'p','b','i','t','s' or
                     'pol', 'beam', 'if', 'time', 'scan'
            default: 'p'
            example: maximum of 25 stacked spectra
                     stack by pol, beam, if, time, scan
    panel -- code for splitting into multiple panels
            options: 'p','b','i','t','s' or
                     'pol', 'beam', 'if', 'time', 'scan'
            default: 'i'
            example: maximum of 25 panels
                     panel by pol, beam, if, time, scan
    flrange -- range for flux axis of plot
            options: (list) [min,max]
            default: [] (full range)
            example: flrange=[-0.1,2.0] if 'K'
                     assumes current fluxunit
    sprange -- range for spectral axis of plot
            options: (list) [min,max]
            default: [] (full range)
            example: sprange=[42.1,42.5] if 'GHz'
                     assumes current specunit
    linecat -- control for line catalog plotting
            options: (str) 'all','none' or by molecule
            default: 'none' (no lines plotted)
            example: linecat='SiO' for SiO lines
                     linecat='*OH' for alcohols
                     uses sprange to limit catalog
            WARNING: specunit must be in frequency (*Hz)
                     to plot from the line catalog!
                     and must be 'GHz' or 'MHz' to use 
                     sprange to limit catalog
    linedop -- doppler offset for line catalog plotting
            options: (float) doppler velocity (km/s)
            default: 0.0
            example: linedop=-30.0
    plotfile -- file name for hardcopy output
            options: (str) filename.eps,.ps,.png
            default: '' (no hardcopy)
            example: 'specplot.eps','specplot.png'
                     Note this autodetects the format from
                     the suffix (.eps,.ps,.png).
\end{verbatim}
    
    DESCRIPTION:
    
    Task {\tt sdplot} displays single-dish spectra.  
    It assumes that the spectra have been calibrated in {\tt sdcal}.
    It does allow selection of scans, IFs, polarizations, and
    some time and channel averaging/smoothing options also,
    but does not write out this data.
    
    Some plot options, like annotation and changing titles,
    legends, colors, fonts, and the like are not supported
    in this task.  You should use {\tt sd.plotter} from the ASAP
    toolkit directly for this.
    
    This task uses the JPL line catalog as supplied by ASAP.
    If you wish to use a different catalog, or have it plot
    the line IDs from top or bottom (rather than alternating),
    then you will need to explore the {\tt sd} toolkit also.	
    
    Note that multiple scans and IFs can in principle be handled
    through stacking and paneling, but this is fairly rudimentary
    at present and you have little control of what happens in
    individual panels.  We recommend that you use {\tt scanlist}, 
    {\tt field}, and {\tt iflist} to give a single selection for each run.
    
    Currently, setting {\tt specunit = 'GHz'} fixes the x-axis span of
    each IF panel to be the same (an example of the limitations
    of ASAP plotting at present).
    
    See the {\tt sdcal} description for information on {\tt fluxunit} 
    conversion and the {\tt telescope} parameter.

    WARNING: be careful plotting OTF (on-the-fly) mosaic data with 
    lots of fields!

\item {\bf sdstat}

\begin{verbatim}
    Keyword arguments:
    sdfile -- name of input SD dataset
            default: none - must input file name
            example: 'mysd.asap'
                     See sdcal for allowed formats.
    telescope -- the telescope name or characteristics
            options: (str) name or (list) list of gain info
            default: '' (none set)
            example: telescope='GBT' for the GBT
                     telescope='AT' for one of the default scopes
                     known to ASAP.
                     telescope=[104.9,0.43] diameter(m), ap.eff.
                     telescope=[0.743] gain in Jy/K
                     telescope='FIX' to change default fluxunit
                     see description below
    fluxunit -- units for line flux
            options: 'K','Jy',''
            default: '' (keep current fluxunit)
            WARNING: For GBT data, see description below.
    specunit -- units for spectral axis
            options: 'channel','km/s','GHz','MHz','kHz','Hz',''
            default: '' (keep current specunit)
            example: make sure this is the same units of masklist
    frame -- frequency frame for spectral axis
            options: (str) 'LSRK','REST','TOPO','LSRD','BARY',
                     'GEO','GALACTO','LGROUP','CMB'
            default: currently set frame in scantable
    doppler -- doppler mode
            options: (str) 'RADIO','OPTICAL','Z','BETA','GAMMA'
            default: currently set doppler in scantable
    scanlist -- list of scan numbers to process
            default: [] (use all scans)
            example: [21,22,23,24]
    field -- selection string for selecting scans by name
            default: '' (no name selection)
            example: 'FLS3a*'
                     this selection is in addition to scanlist
                     and iflist
    iflist -- list of IF id numbers to select
            default: [] (use all IFs)
            example: [15]
    masklist -- list of mask regions to INCLUDE in stats
            default: [] (whole spectrum)
            example: [4000,4500] for one region
                     [[1000,3000],[5000,7000]]
                     these must be pairs of [lo,hi] boundaries
    invertmask -- invert mask (EXCLUDE masklist instead)
            options: (bool) True,False
            default: false
    
    -------------------------------------------------------------------
    xstat -- RETURN ONLY: a Python dictionary of line statistics
               keys: 'rms','stddev','max','min','sum','median','mean',
                     'eqw'
            example: print "rms = ",xstat['rms']
                     these can be used for testing in scripts or
                     for regression
                     
                     'eqw' is equivalent width (sum/mag) where mag
                     is either max or min depending on which has
                     greater magnitude.
\end{verbatim}
    
    DESCRIPTION:
    
    Task {\tt sdstat} computes basic statistics (rms, mean, median, 
    sum) for single-dish spectra.  It assumes that the spectra have
    been calibrated in {\tt sdcal}.  Furthermore, it assumes that any
    selection of scans, IFs, polarizations, and time and channel
    averaging/smoothing has also already been done (in {\tt sdcal}) as
    there are no controls for these.  Note that you can run {\tt sdcal}
    with {\tt calmode = 'none'} and do selection, writing out a new
    scantable.
    
    Note that multiple scans and IFs can in principle be handled, but
    we recommend that you use scanlist, field, and iflist to give a
    single selection for each run.
    
    See the {\tt sdcal} description for information on {\tt fluxunit} 
    conversion and the {\tt telescope} parameter.

    WARNING: If you do have multiple scantable rows, then {\tt xstat}
    values will be lists.
    
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A Single Dish Analysis Use Case With SDTasks}
\label{section:sd.sdtasks.usecase}

As an example, the following illustrates the use of the SDtasks for
the Orion data set, which contains the HCCCN line in one of its IFs.
This walk-through contains comments about setting parameter values
and some options during processing.

\begin{verbatim}
#####################################
#
# ORION-S SDtasks Use Case
# Position-Switched data
# Version STM 2007-03-04
#
# This is a detailed walk-through
# for using the SDtasks on a
# test dataset.
#
#####################################
import time
import os

# NOTE: you should have already run
# asap_init()
# to import the ASAP tools as sd.<tool>
# and the SDtasks

#
# This is the environment variable
# pointing to the head of the CASA
# tree that you are running
casapath=os.environ['AIPSPATH']

#
# This bit removes old versions of the output files
os.system('rm -rf sdusecase_orions* ')
#
# This is the path to the OrionS GBT ms in the data repository
datapath=casapath+'/data/regression/ATST5/OrionS/OrionS_rawACSmod'
#
# The follwing will remove old versions of the data and
# copy the data from the repository to your
# current directory.  Comment this out if you already have it
# and don't want to recopy
os.system('rm -rf OrionS_rawACSmod')
copystring='cp -r '+datapath+' .'
os.system(copystring)

# This resets all of the CASA task parameters to their
# global defaults.  Note that these are not necessarily
# the proper defaults for specific tasks (see below).
restore()

# Now is the time to set some of the more useful
# ASAP environment parameters (the ones that the
# ASAP User Manual claims are in the .asaprc file).
# These are in the Python dictionary sd.rcParams
# You can see whats in it by typing:
#sd.rcParams
# One of them is the 'verbose' parameter which tells
# ASAP whether to spew lots of verbiage during processing
# or to keep quiet.  The default is
#sd.rcParams['verbose']=True
# You can make ASAP run quietly (with only task output) with
#sd.rcParams['verbose']=False

# Another key one is to tell ASAP to save memory by
# going off the disk instead.  The default is
#sd.rcParams['scantable.storage']='memory'
# but if you are on a machine with small memory, do
#sd.rcParams['scantable.storage']='disk'

# You can reset back to defaults with
#sd.rcdefaults

##########################
#
# ORION-S HC3N
# Position-Switched data
#
##########################
startTime=time.time()
startProc=time.clock()

##########################
# List data
##########################
# List the contents of the dataset
# First reset parameter defaults (safe)
default('sdlist')

# You can see its inputs with
#inp('sdlist')
# or just
#inp
# now that the defaults('sdlist') set the
# taskname='sdlist'
#
# Set the name of the GBT ms file
infile = 'OrionS_rawACSmod'

# Set an output file in case we want to
# refer back to it
listfile = 'sdusecase_orions_summary.txt'
sdlist()

# You could also just type
#go

# You should see something like:
#
#--------------------------------------------------------------------------------
# Scan Table Summary
#--------------------------------------------------------------------------------
#Beams:         1   
#IFs:           26  
#Polarisations: 2   (linear)
#Channels:      8192
#
#Observer:      Joseph McMullin
#Obs Date:      2006/01/19/01:45:58
#Project:       AGBT06A_018_01
#Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
#Antenna Name:  GBT
#Flux Unit:     Jy
#Rest Freqs:    [4.5490258e+10] [Hz]
#Abcissa:       Channel
#Selection:     none
#
#Scan Source         Time      Integration       
#     Beam    Position (J2000)
#          IF       Frame   RefVal          RefPix    Increment   
#--------------------------------------------------------------------------------
#  20 OrionS_psr     01:45:58    4 x       30.0s
#        0    05:15:13.5 -05.24.08.2
#            0      LSRK   4.5489354e+10   4096    6104.233
#            1      LSRK   4.5300785e+10   4096    6104.233
#            2      LSRK   4.4074929e+10   4096    6104.233
#            3      LSRK   4.4166215e+10   4096    6104.233
#  21 OrionS_ps      01:48:38    4 x       30.0s
#        0    05:35:13.5 -05.24.08.2
#            0      LSRK   4.5489354e+10   4096    6104.233
#            1      LSRK   4.5300785e+10   4096    6104.233
#            2      LSRK   4.4074929e+10   4096    6104.233
#            3      LSRK   4.4166215e+10   4096    6104.233
#  22 OrionS_psr     01:51:21    4 x       30.0s
#        0    05:15:13.5 -05.24.08.2
#            0      LSRK   4.5489354e+10   4096    6104.233
#            1      LSRK   4.5300785e+10   4096    6104.233
#            2      LSRK   4.4074929e+10   4096    6104.233
#            3      LSRK   4.4166215e+10   4096    6104.233
#  23 OrionS_ps      01:54:01    4 x       30.0s
#        0    05:35:13.5 -05.24.08.2
#            0      LSRK   4.5489354e+10   4096    6104.233
#            1      LSRK   4.5300785e+10   4096    6104.233
#            2      LSRK   4.4074929e+10   4096    6104.233
#            3      LSRK   4.4166215e+10   4096    6104.233
#  24 OrionS_psr     02:01:47    4 x       30.0s
#        0    05:15:13.5 -05.24.08.2
#           12      LSRK   4.3962126e+10   4096   6104.2336
#           13      LSRK    4.264542e+10   4096   6104.2336
#           14      LSRK    4.159498e+10   4096   6104.2336
#           15      LSRK   4.3422823e+10   4096   6104.2336
#  25 OrionS_ps      02:04:27    4 x       30.0s
#        0    05:35:13.5 -05.24.08.2
#           12      LSRK   4.3962126e+10   4096   6104.2336
#           13      LSRK    4.264542e+10   4096   6104.2336
#           14      LSRK    4.159498e+10   4096   6104.2336
#           15      LSRK   4.3422823e+10   4096   6104.2336
#  26 OrionS_psr     02:07:10    4 x       30.0s
#        0    05:15:13.5 -05.24.08.2
#           12      LSRK   4.3962126e+10   4096   6104.2336
#           13      LSRK    4.264542e+10   4096   6104.2336
#           14      LSRK    4.159498e+10   4096   6104.2336
#           15      LSRK   4.3422823e+10   4096   6104.2336
#  27 OrionS_ps      02:09:51    4 x       30.0s
#        0    05:35:13.5 -05.24.08.2
#           12      LSRK   4.3962126e+10   4096   6104.2336
#           13      LSRK    4.264542e+10   4096   6104.2336
#           14      LSRK    4.159498e+10   4096   6104.2336
#           15      LSRK   4.3422823e+10   4096   6104.2336

# The HC3N and CH3OH lines are in IFs 0 and 2 respectively
# of scans 20,21,22,23.  We will pull these out in our
# calibration.

##########################
# Calibrate data
##########################
# We will use the sdcal task to calibrate the data.
# Set the defaults
default('sdcal')

# You can see the inputs with
#inp

# Set our infile (which would have been set from our run of
# sdlist if we were not cautious and reset defaults).
infile = 'OrionS_rawACSmod'

# Currently, the ASAP scantable filler does not fully recognize
# data from the GBT, and it thinks that the data is in 'Jy'
# (what it does when it doesn't know any better) instead of
# 'K', which is what it really is.  So we tell sdcal to fix
# this for us:
telescope = 'FIX'
fluxunit = 'K'

# Lets leave the spectral axis in channels for now
specunit = 'channel'

# This is position-switched data so we tell sdcal this
calmode = 'ps'

# For GBT data, it is safest to not have scantable pre-average
# integrations within scans.
scanaverage = False

# We do want sdcal to average up scans and polarization after
# calibration however.
timeaverage = True
polaverage = True

# Do an atmospheric optical depth (attenuation) correction
# Input the zenith optical depth at 43 GHz
tau = 0.09

# Select our scans and IFs (for HC3N)
scanlist = [20,21,22,23]
iflist = [0]

# We do not require selection by field name (they are all
# the same except for on and off)
field = ''

# We will do some spectral smoothing
# For this demo we will use boxcar smoothing rather than
# the default
#kernel='hanning'
# We will set the width of the kernel to 5 channels
kernel = 'boxcar'
kwidth = 5

# We wish to fit out a baseline from the spectrum
# The GBT has particularly nasty baselines :(
# We will let ASAP use auto_poly_baseline mode
# but tell it to drop the 1000 edge channels from
# the beginning and end of the spectrum.
# A 2nd-order polynomial will suffice for this test.
# You might try higher orders for fun.
blmode = 'auto'
blpoly = 2
edge = [1000]

# We will not give it regions as an input mask
# though you could, with something like
#masklist=[[1000,3000],[5000,7000]]
masklist = []

# By default, we will not get plots in sdcal (but
# can make them using sdplot).
plotlevel = 0
# But if you wish to see a final spectrum, set
#plotlevel = 1
# or even
#plotlevel = 2
# to see intermediate plots and baselining output.

# Now we give the name for the output file
sdfile = 'sdusecase_orions_hc3n.asap'

# We will write it out in ASAP scantable format
outform = 'asap'

# You can look at the inputs with
#inp

# Before running, lets save the inputs in case we want
# to come back and re-run the calibration.
saveinputs('sdcal','sdcal.orions.save')
# These can be recovered by
#execfile 'sdcal.orions.save'

# We are ready to calibrate
sdcal()

# Note that after the task ran, it produced a file
# sdcal.last which contains the inputs from the last
# run of the task (all tasks do this). You can recover
# this (anytime before sdcal is run again) with
#execfile 'sdcal.last'

##########################
# List data
##########################
# List the contents of the calibrated dataset
# Set the input to the just created file
infile = sdfile
listfile = ''
sdlist()

# You should see:
#
#--------------------------------------------------------------------------------
# Scan Table Summary
#--------------------------------------------------------------------------------
#Beams:         1   
#IFs:           26  
#Polarisations: 1   (linear)
#Channels:      8192
#
#Observer:      Joseph McMullin
#Obs Date:      2006/01/19/01:45:58
#Project:       AGBT06A_018_01
#Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
#Antenna Name:  GBT
#Flux Unit:     K
#Rest Freqs:    [4.5490258e+10] [Hz]
#Abcissa:       Channel
#Selection:     none
#
#Scan Source         Time      Integration       
#     Beam    Position (J2000)
#          IF       Frame   RefVal          RefPix    Increment   
#--------------------------------------------------------------------------------
#   0 OrionS_ps      01:52:05    1 x    08:00.5 
#        0    05:35:13.5 -05.24.08.2
#            0      LSRK   4.5489354e+10   4096    6104.233
#
# Note that our scans are now collapsed (timeaverage=True) but 
# we still have our IF 0

##########################
# Plot data
##########################
default('sdplot')

# The file we produced after calibration
# (if we hadn't reset defaults it would have
# been set - note that sdplot,sdfit,sdstat use
# sdfile as the input file, which is the output
# file of sdcal).
sdfile = 'sdusecase_orions_hc3n.asap'

# Lets just go ahead and plot it up as-is
sdplot()

# Looks ok.  Plot with x-axis in GHz
specunit='GHz'
sdplot()

# Note that the rest frequency in the scantable
# is set correctly to the HCCCN line at 45.490 GHz.
# So you can plot the spectrum in km/s
specunit='km/s'
sdplot()

# Zoom in
sprange=[-100,50]
sdplot()

# Lets plot up the lines to be sure
# We have to go back to GHz for this
# (known deficiency in ASAP)
specunit='GHz'
sprange=[45.48,45.51]
linecat='all'
sdplot()

# Too many lines! Focus on the HC3N ones
linecat='HCCCN'
sdplot()

# Finally, we can convert from K to Jy
# using the aperture efficiencies we have
# coded into the sdtasks
telescope='GBT'
fluxunit='Jy'
sdplot()

# Lets save this plot
plotfile='sdusecase_orions_hc3n.eps'
sdplot()

##########################
# Off-line Statistics
##########################
# Now do some region statistics
# First the line-free region
# Set parameters
default('sdstat')
sdfile = 'sdusecase_orions_hc3n.asap'

# Keep the default spectrum and flux units
# K and channel
fluxunit = ''
specunit = ''

# Pick out a line-free region
# You can bring up a default sdplot again
# to check this
masklist = [[5000,7000]]

# This is a line-free region so we don't need
# to invert the mask
invertmask = False

# You can check with
#inp

sdstat()

# You see that sdstat returns some results in
# the Python dictionary xstat.  You can assign
# this to a variable
off_stat = xstat

# and look at it
off_stat
# which should give
# {'eqw': 38.563105620704945,
#  'max': 0.15543246269226074,
#  'mean': -0.0030361821409314871,
#  'median': -0.0032975673675537109,
#  'min': -0.15754437446594238,
#  'rms': 0.047580458223819733,
#  'stddev': 0.047495327889919281,
#  'sum': -6.0754003524780273}


#You see it has some keywords for the various
#stats.  We want the standard deviation about
#the mean, or 'stddev'
print "The off-line std. deviation = ",off_stat['stddev']
# which should give
# The off-line std. deviation =  0.0474953278899

# or better formatted (using Python I/O formatting)
print "The off-line std. deviation = %5.3f K" %\
      (off_stat['stddev'])
# which should give
# The off-line std. deviation = 0.047 K

##########################
# On-line Statistics
##########################
# Now do the line region
# Continue setting or resetting parameters
masklist = [[3900,4200]]

sdstat()

line_stat = xstat

# look at these
line_stat
# which gives
# {'eqw': 73.335154614280981,
#  'max': 0.92909121513366699,
#  'mean': 0.22636228799819946,
#  'median': 0.10317134857177734,
#  'min': -0.13283586502075195,
#  'rms': 0.35585442185401917,
#  'stddev': 0.27503398060798645,
#  'sum': 68.135047912597656}

# of particular interest are the max value
print "The on-line maximum = %5.3f K" % (line_stat['max'])
# which gives
# The on-line maximum = 0.929 K

# and the estimated equivalent width (in channels)
# which is the sum/max
print "The estimated equivalent width = %5.1f channels" %\
      (line_stat['eqw'])
# which gives
# The estimated equivalent width =  73.3 channels

##########################
# Line Fitting
##########################
# Now we are ready to do some line fitting
# Default the parameters
default('sdfit')

# Set our input file
sdfile = 'sdusecase_orions_hc3n.asap'

# Stick to defaults
# fluxunit = 'K', specunit = 'channel'
fluxunit = ''
specunit = ''

# We will try auto-fitting first
fitmode = 'auto'
# A single Gaussian
nfit = [1]
# Leave the auto-parameters to their defaults for
# now, except ignore the edge channels
edge = [1000]

# Lets see a plot while doing this
plotlevel = 1

# Save the fit output in a file
fitfile = 'sdusecase_orions_hc3n.fit'

# Go ahead and do the fit
sdfit()

# If you had verbose mode on, you probably saw something
# like:
#
# 0: peak = 0.811 K , centre = 4091.041 channel, FWHM = 72.900 channel
#    area = 62.918 K channel
#

# The fit is output in the dictionary xstat
fit_stat = xstat

fit_stat
#
# {'cent': [[4091.04052734375, 0.72398632764816284]],
#  'fwhm': [[72.899894714355469, 1.7048574686050415]],
#  'nfit': 1,
#  'peak': [[0.81080442667007446, 0.016420882195234299]]}
#
# So you can write them out or test them:
print "The line-fit parameters were:"
print "      maximum = %6.3f +/- %6.3f K" %\
      (fit_stat['peak'][0][0],fit_stat['peak'][0][1])
print "       center = %6.1f +/- %6.1f channels" %\
      (fit_stat['cent'][0][0],fit_stat['cent'][0][1])
print "         FWHM = %6.2f +/- %6.2f channels" %\
      (fit_stat['fwhm'][0][0],fit_stat['fwhm'][0][1])
#
# Which gives:
# The line-fit parameters were:
#       maximum =  0.811 +/-  0.016 K
#        center = 4091.0 +/-    0.7 channels
#          FWHM =  72.90 +/-   1.70 channels

# We can do the fit in km/s also
specunit = 'km/s'
# For some reason we need to help it along with a mask
maskline = [-50,0]

fitfile = 'sdusecase_orions_hc3n_kms.fit'
sdfit()
# Should give (if in verbose mode)
#   0: peak = 0.811 K , centre = -27.134 km/s, FWHM = 2.933 km/s
#      area = 2.531 K km/s
#
# or

fit_stat_kms = xstat

# with
fit_stat_kms
# giving
# {'cent': [[-27.133651733398438, 0.016480101272463799]],
#  'fwhm': [[2.93294358253479, 0.038807671517133713]],
#  'nfit': 1,
#  'peak': [[0.81080895662307739, 0.0092909494414925575]]}


print "The line-fit parameters were:"
print "      maximum = %6.3f +/- %6.3f K" %\
      (fit_stat_kms['peak'][0][0],fit_stat_kms['peak'][0][1])
print "       center = %6.2f +/- %6.2f km/s" %\
      (fit_stat_kms['cent'][0][0],fit_stat_kms['cent'][0][1])
print "         FWHM = %6.4f +/- %6.4f km/s" %\
      (fit_stat_kms['fwhm'][0][0],fit_stat_kms['fwhm'][0][1])

# The line-fit parameters were:
#       maximum =  0.811 +/-  0.009 K
#        center = -27.13 +/-   0.02 km/s
#          FWHM = 2.9329 +/- 0.0388 km/s

##########################
#
# End ORION-S Use Case
#
##########################
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Using The ASAP Toolkit Within CASA}
\label{section:sd.asap}

ASAP is included with the CASA installation/build. It is not loaded
upon start-up, however, and must be imported as a standard Python
package. A convenience function exists for importing ASAP along with
a set of prototype tasks for single dish analysis:
\small
\begin{verbatim}
  CASA <1>: asap_init
\end{verbatim}
\normalsize
Once this is done, all of the ASAP functionality is now under the
Python 'sd' tool.  {bf: Note: This means that if you are following
the ASAP cookbook or documentation, all of the commands should be 
invoked with a 'sd.' before the native ASAP command.}

The ASAP interface is essentially the same as that
of the CASA toolkit, that is, there are groups of functionality (aka
tools) which have the ability to operate on your data. Type:

\small
\begin{verbatim}
  CASA <4>: sd.<TAB>
  sd.__class__               sd._validate_bool          sd.list_scans
  sd.__date__                sd._validate_int           sd.mask_and
  sd.__delattr__             sd.asapfitter              sd.mask_not
  sd.__dict__                sd.asaplinefind            sd.mask_or
  sd.__doc__                 sd.asaplog                 sd.merge
  sd.__file__                sd.asaplotbase             sd.os
  sd.__getattribute__        sd.asaplotgui              sd.plf
  sd.__hash__                sd.asapmath                sd.plotter
  sd.__init__                sd.asapplotter             sd.print_log
  sd.__name__                sd.asapreader              sd.quotient
  sd.__new__                 sd.average_time            sd.rc
  sd.__path__                sd.calfs                   sd.rcParams
  sd.__reduce__              sd.calnod                  sd.rcParamsDefault
  sd.__reduce_ex__           sd.calps                   sd.rc_params
  sd.__repr__                sd.commands                sd.rcdefaults
  sd.__setattr__             sd.defaultParams           sd.reader
  sd.__str__                 sd.dosigref                sd.scantable
  sd.__version__             sd.dototalpower            sd.selector
  sd._asap                   sd.fitter                  sd.simple_math
  sd._asap_fname             sd.is_ipython              sd.sys
  sd._asaplog                sd.linecatalog             sd.unique
  sd._is_sequence_or_number  sd.linefinder              sd.version
  sd._n_bools                sd.list_files              sd.welcome
  sd._to_list                sd.list_rcparameters       sd.xyplotter
\end{verbatim}
\normalsize

...to see the list of tools.

In particular, the following are essential for most reduction
sessions: 
\begin{itemize}
   \item {\tt sd.scantable} - the data structure for ASAP and the core
         methods for manipulating the data; allows importing data,
         making data selections, basic operations (averaging,
         baselines, etc) and setting data characteristics (e.g.,
         frequencies, etc).
   \item {\tt sd.selector} - selects a subset of data for subsequent operations
   \item {\tt sd.fitter} - fit data 
   \item {\tt sd.plotter} - plotting facilities (uses {\tt matplotlib})
\end{itemize}

The {\tt scantable} functions are used most often and can be applied
to both the initial scantable and to any spectrum from that scan
table.  Type
\small
\begin{verbatim}
     sd.scantable.<TAB>
\end{verbatim}
\normalsize
(using TAB completion) to see the full list. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Environment Variables}
\label{subsection:sd.asap.environ}

The {\tt asaprc} environment variables are stored in the Python
dictionary {\tt sd.rcParams} in CASA.  This contains a number
of parameters that control how ASAP runs, for both tools and
tasks.  You can see what these are set to by typing at the
CASA prompt:

\small
\begin{verbatim}
  CASA <2>: sd.rcParams
  Out[2]: 
{'insitu': True,
 'plotter.colours': '',
 'plotter.decimate': False,
 'plotter.ganged': True,
 'plotter.gui': True,
 'plotter.histogram': False,
 'plotter.linestyles': '',
 'plotter.panelling': 's',
 'plotter.papertype': 'A4',
 'plotter.stacking': 'p',
 'scantable.autoaverage': True,
 'scantable.freqframe': 'LSRK',
 'scantable.save': 'ASAP',
 'scantable.storage': 'memory',
 'scantable.verbosesummary': False,
 'useplotter': True,
 'verbose': True}
\end{verbatim}
\normalsize

The use of these parameters is described in detail in the
ASAP Users Guide.

You can also change these parameters through the {\tt sd.rc}
function.  The use of this is described in {\tt help sd.rc}:

\small
\begin{verbatim}
CASA <3>: help(sd.rc)
Help on function rc in module asap:

rc(group, **kwargs)
    Set the current rc params.  Group is the grouping for the rc, eg
    for scantable.save the group is 'scantable', for plotter.stacking, the
    group is 'plotter', and so on.  kwargs is a list of attribute
    name/value pairs, eg
    
      rc('scantable', save='SDFITS')
    
    sets the current rc params and is equivalent to
    
      rcParams['scantable.save'] = 'SDFITS'
    
    Use rcdefaults to restore the default rc params after changes.
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Import}
\label{subsection:sd.asap.import}

Data can be loaded into ASAP by using the {\tt scantable} function
which will read a variety of recognized formats (RPFITS, varieties of
SDFITS, and the CASA Measurement Set). For example:


\small
\begin{verbatim}
  CASA <1>: scans = sd.scantable('OrionS_rawACSmod', average=False)
  Importing OrionS_rawACSmod...
\end{verbatim}
\normalsize

{\bf NOTE:} It is important to use the {\tt average=False} parameter
setting as the calibration routines supporting GBT data require all of
the individual times and phases.

{\bf NOTE:} GBT data may need some pre-processing prior to using
ASAP. In particular, the program which converts GBT raw data into CASA
Measurement Sets tends to proliferate the number of spectral windows
due to shifts in the tracking frequency; this is being worked on by
GBT staff. In addition, GBT SDFITS is currently not readable by ASAP
(in progress).

{\bf NOTE:} The Measurement Set to scantable conversion is able to deduce
the reference and source data and assigns an '\_r' to the reference
data to comply with the ASAP conventions.

{\bf NOTE:} GBT observing modes are identifiable in scantable in the
name assignment: position switched ('\_ps'), Nod ('\_nod'), and
frequency switched ('\_fs'). These are combined with the reference data
assignment. (For example, the reference data taken in position
switched mode observation are assigned as '\_psr'.)

Use the {\tt summary} function to examine the data and get basic information:

\small
\begin{verbatim}
CASA <8>: scans.summary()
--------------------------------------------------------------------------------
 Scan Table Summary
--------------------------------------------------------------------------------
Beams:         1   
IFs:           26  
Polarisations: 2   (linear)
Channels:      8192

Observer:      Joseph McMullin
Obs Date:      2006/01/19/01:45:58
Project:       AGBT06A_018_01
Obs. Type:     OffOn:PSWITCHOFF:TPWCAL
Antenna Name:  GBT
Flux Unit:     Jy
Rest Freqs:    [4.5490258e+10] [Hz]
Abcissa:       Channel
Selection:     none

Scan Source         Time      Integration       
     Beam    Position (J2000)
          IF       Frame   RefVal          RefPix    Increment   
--------------------------------------------------------------------------------
  20 OrionS_psr     01:45:58    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  21 OrionS_ps      01:48:38    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  22 OrionS_psr     01:51:21    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  23 OrionS_ps      01:54:01    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
            0      LSRK   4.5489354e+10   4096    6104.233
            1      LSRK   4.5300785e+10   4096    6104.233
            2      LSRK   4.4074929e+10   4096    6104.233
            3      LSRK   4.4166215e+10   4096    6104.233
  24 OrionS_psr     02:01:47    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  25 OrionS_ps      02:04:27    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  26 OrionS_psr     02:07:10    4 x       30.0s
        0    05:15:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
  27 OrionS_ps      02:09:51    4 x       30.0s
        0    05:35:13.5 -05.24.08.2
           12      LSRK   4.3962126e+10   4096   6104.2336
           13      LSRK    4.264542e+10   4096   6104.2336
           14      LSRK    4.159498e+10   4096   6104.2336
           15      LSRK   4.3422823e+10   4096   6104.2336
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scantable Manipulation}
\label{subsection:sd.asap.scantable}

Within ASAP, data is stored in a {\tt scantable}, which holds all of the
observational information and provides functionality to manipulate the
data and information. The building block of a {\tt scantable} is an
integration which is a single row of a scantable. Each row contains
just one spectrum for each beam, IF and polarization.  

Once you have a {\tt scantable} in ASAP, you can select a subset of the
data based on scan numbers, sources, or types of scan; note that each
of these selections returns a new 'scantable' with all of the 
underlying functionality: 

\small
\begin{verbatim}
  CASA <5>: scan27=scans.get_scan(27)                 # Get the 27th scan
  CASA <6>: scans20to24=scans.get_scan(range(20,25))  # Get scans 20 - 24
  CASA <7>: scans_on=scans.get_scan('*_ps')           # Get ps scans on source
  CASA <8>: scansOrion=scans.get_scan('Ori*')         # Get all Orion scans
\end{verbatim}
\normalsize

To copy a scantable, do:

\small
\begin{verbatim}
  CASA <15>: ss=scans.copy()
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data Selection}
\label{subsubsection:sd.asap.scantable.select}

In addition to the basic data selection above, data can be selected
based on IF, beam, polarization, scan number as well as values such as
Tsys.  To make a selection you create a {\tt selector} object which
you then define with various selection functions, e.g.,

\small
\begin{verbatim}
  sel = sd.selector()      # initialize a selector object
                           # sel.<TAB> will list all options
  sel.set_ifs(0)           # select only the first IF of the data
  scans.set_selection(sel) # apply the selection to the data
  print scans              # shows just the first IF
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{State Information}
\label{subsubsection:sd.asap.scantable.state}

Some properties of a scantable apply to all of the data, such as
example, spectral units, frequency frame, or Doppler type. This
information can be set using the {\tt scantable} \_set\_xxxx\_
methods.  These are currently:
\small
\begin{verbatim}
CASA <1>: sd.scantable.set_<TAB>
sd.scantable.set_dirframe    sd.scantable.set_fluxunit    sd.scantable.set_restfreqs   
sd.scantable.set_doppler     sd.scantable.set_freqframe   sd.scantable.set_selection   
sd.scantable.set_feedtype    sd.scantable.set_instrument  sd.scantable.set_unit
\end{verbatim}
\normalsize

For example, {\tt sd.scantable.set\_fluxunit} sets the default units
that describe the flux axis:
\small
\begin{verbatim}
  scans.set_fluxunit('K')  # Set the flux unit for data to Kelvin
\end{verbatim}
\normalsize
Choices are {\tt 'K'} or {\tt 'Jy'}.
Note: the scantable.set\_fluxunit function only changes the {\bf name}
of the current fluxunit. To change fluxunits, use 
{\tt scantable.convert\_flux} as described in 
\S~\ref{subsubsection:sd.asap.calib.fluxunit}
instead (currently you need to do some gymnastics for GBT or non-AT
telescopes).

Use {\tt sd.scantable.set\_unit} to set the units to be used on 
the spectral axis:
\small
\begin{verbatim}
  scans.set_unit('GHz')    # Use GHZ as the spectral axis for plots
\end{verbatim}
\normalsize
The choices for the units are {\tt 'km/s'}, {\tt 'channel'}, or
{\tt '*Hz'} (e.g. {\tt 'GHz'}, {\tt 'MHz'}, {\tt 'kHz'}, {\tt 'Hz'}).
This does the proper conversion using the current frame and Doppler
reference as can be seen when the spectrum is plotted.

You can use {\tt sd.scantable.set\_freqframe}
to set the frame in which the frequency (spectral) axis is defined:
\small
\begin{verbatim}
CASA <2>: help(sd.scantable.set_freqframe)
Help on method set_freqframe in module asap.scantable:

set_freqframe(self, frame=None) unbound asap.scantable.scantable method
    Set the frame type of the Spectral Axis.
    Parameters:
        frame:   an optional frame type, default 'LSRK'. Valid frames are:
                 'REST', 'TOPO', 'LSRD', 'LSRK', 'BARY',
                 'GEO', 'GALACTO', 'LGROUP', 'CMB'
    Examples:
        scan.set_freqframe('BARY')
\end{verbatim}
\normalsize
The most useful choices here are {\tt frame = 'LSRK'} (the default for
the function) and {\tt frame = 'TOPO'} (what the GBT actually observes
in).  Note that the {\tt 'REST'} option is not yet available.
The Doppler frame is set with {\tt sd.scantable.set\_doppler}:
\small
\begin{verbatim}
CASA <3>: help(sd.scantable.set_doppler)
Help on method set_doppler in module asap.scantable:

set_doppler(self, doppler='RADIO') unbound asap.scantable.scantable method
    Set the doppler for all following operations on this scantable.
    Parameters:
        doppler:    One of 'RADIO', 'OPTICAL', 'Z', 'BETA', 'GAMMA'
\end{verbatim}
\normalsize

Finally, there are a number of functions to query the state of the
scantable.  These can be found in the usual way:
\small
\begin{verbatim}
CASA <4>: sd.scantable.get<TAB>
sd.scantable.get_abcissa       sd.scantable.get_restfreqs     sd.scantable.getbeamnos
sd.scantable.get_azimuth       sd.scantable.get_scan          sd.scantable.getcycle
sd.scantable.get_column_names  sd.scantable.get_selection     sd.scantable.getif
sd.scantable.get_direction     sd.scantable.get_sourcename    sd.scantable.getifnos
sd.scantable.get_elevation     sd.scantable.get_time          sd.scantable.getpol
sd.scantable.get_fit           sd.scantable.get_tsys          sd.scantable.getpolnos
sd.scantable.get_fluxunit      sd.scantable.get_unit          sd.scantable.getscan
sd.scantable.get_parangle      sd.scantable.getbeam           sd.scantable.getscannos
\end{verbatim}
\normalsize
These include functions to get the current values of the states
mentioned above, as well as
as methods to query the number of scans, IFs, and polarizations
in the scantable, and their designations.  See the
inline help for the individual functions for more information.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Masks}
\label{subsubsection:sd.asap.scantable.masks}

Several functions (fitting, baseline subtraction, statistics, etc) may
be run on a range of channels (or velocity/frequency ranges). You can
create masks of this type using the {\tt create\_mask} function:

\small
\begin{verbatim}
  # spave = an averaged spectrum
  spave.set_unit('channel')
  rmsmask=spave.create_mask([5000,7000])   # create a region over channels 5000-7000
  rms=spave.stats(stat='rms',mask=rmsmask) # get rms of line free region

  rmsmask=spave.create_mask([3000,4000],invert=True) # choose the region 
                                                     # *excluding* the specified channels
\end{verbatim}
\normalsize

The mask is stored in a simple Python variable (a list) and so may be
manipulated using an Python facilities. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Management}
\label{subsubsection:sd.asap.scantable.management}

{\tt scantables} can be listed via:

\small
\begin{verbatim}
  CASA <33>: sd.list_scans()
  The user created scantables are:
  ['scans20to24', 's', 'scan27']
\end{verbatim}
\normalsize

As every {\tt scantable} will consume memory, if you will not use it
any longer, you can explicitly remove it via:

\small
\begin{verbatim}
  del <scantable name>
\end{verbatim}
\normalsize
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Mathematics}
\label{subsubsection:sd.asap.scantable.scanmath}

It is possible to do simple mathematics directly on {\tt scantables}
from the CASA command line using the $+,-,*,/$ operators as well as
their cousins $+=, -=, *=, /=$

\small
\begin{verbatim}
  CASA <10>: scan2=scan1+2.0 # add 2.0 to data 
  CASA <11>: scan *= 1.05    # scale spectrum by 1.05 
\end{verbatim}
\normalsize

{\bf NOTE:} mathematics between two scantables is not currently
available in ASAP.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Scantable Save and Export}
\label{subsubsection:sd.asap.scantable.export}

ASAP can save scantables in a variety of formats, suitable for reading
into other packages. The formats are: 

\begin{itemize}
    \item ASAP -- This is the internal format used for ASAP. It is the only
     format that allows the user to restore the data, fits, etc,
     without loosing any information. As mentioned before, the ASAP
     scantable is a CASA Table (memory-based table). This function
     just converts it to a disk-based table. You can access this with
     the CASA {\tt browsetable} task or any other CASA table tasks. 

   \item SDFITS -- The Single Dish FITS format. This format was designed
     for interchange between packages but few packages can actually
     read it. 

   \item ASCII -- A simple text based format suitable for the user to
     process using Python or other means. 

   \item Measurement Set (V2: CASA format) -- Saves the data in a
     Measurement Set. All CASA tasks which use an MS should work on
     this. 
\end{itemize}

\small
\begin{verbatim}
  scans.save('output_filename','format'), e.g.,
  CASA <19>: scans.save('FLS3a_calfs','MS2')
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Calibration}
\label{subsection:sd.asap.calib}

For some observatories, the calibration happens transparently as the
input data contains the Tsys measurements taken during the
observations. The nominal 'Tsys' values may be in Kelvin or
Jansky. The user may wish to apply a Tsys correction or apply
gain-elevation and opacity corrections.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Tsys scaling}
\label{subsubsection:sd.asap.calib.tsys}

If the nominal Tsys measurement at the telescope is wrong due to
incorrect calibration, the {\tt scale} function allows it to be corrected.  

\small
\begin{verbatim}
  scans.scale(1.05,tsys=True) # by default only the spectra are scaled
                              # (and not the corresponding Tsys) unless tsys=True
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Flux and Temperature Unit Conversion}
\label{subsubsection:sd.asap.calib.fluxunit}

To convert measurements in Kelvin to Jansky (and vice versa), the {\tt
convert\_flux} function may be used. This converts and scales the data
to the selected units. The user may need to supply the aperture
efficiency, telescope diameter or the Jy/K factor

\small
\begin{verbatim}
  scans.convert_flux(eta=0.48, d=35.) # Unknown telescope
  scans.convert_flux(jypk=15) # Unknown telecope (alternative)
  scans.convert_flux() # known telescope (mostly AT telescopes)
  scans.convert_flux(eta=0.48) # if telescope diameter known
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Gain-Elevation and Atmospheric Optical Depth Corrections}
\label{subsubsection:sd.asap.calib.gain}

At higher frequencies, it is important to make corrections for
atmospheric opacity and gain-elevation effects. {\bf NOTE:} Currently,
the MS to scantable conversion does not adequately populate the
azimuth and elevation in the {\tt scantable}. As a result, one must
calculate these via:

\small
\begin{verbatim}
  scans.recalc_azel()
  Computed azimuth/elevation using 
  Position: [882590, -4.92487e+06, 3.94373e+06]
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   Time: 01:48:38 Direction: 05:35:13.5 -05.24.08.2
     => azel: 154.696 43.1847 (deg)
   ...
\end{verbatim}
\normalsize


Once you have the correct Az/El, you can correct for a {\it known}
opacity by:

\small
\begin{verbatim}
  scans.opacity(tau=0.09)  # Opacity from which the correction factor: 
                           # exp(tau*zenith-distance)
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Calibration of GBT data}
\label{subsubsection:sd.asap.calib.gbt}

Data from the GBT is uncalibrated and comes as sets of integrations
representing the different phases within a calibration cycle (e.g., on
source, calibration on, on source, calibration off, on reference,
calibration on; on reference, calibration off). Currently, there are a
number of routines emulating the standard GBT calibration (in GBTIDL):
\begin{itemize}
   \item calps - calibrate position switched data
   \item calfs - calibrate frequency switched data
   \item calnod - calibration nod (beam switch) data
\end{itemize}

All these routines calibrate the spectral data to antenna temperature
adopting the GBT calibration method as described in the
GBTIDL calibration document available at: 
\begin{itemize}
   \item \url{http://wwwlocal.gb.nrao.edu/GBT/DA/gbtidl/gbtidl_calibration.pdf}
\end{itemize}
There are two basic steps:

First: determine system temperature using a noise tube calibrator
(sd.dototalpower()) 

For each integration, the system temperature is calculated from
CAL noise on/off data as:

$ T_{sys} = T_{cal}$ x 
$\frac{<ref_{caloff}>}{<ref_{calon} - ref_{caloff}>} + \frac{T_{cal}}{2} $

{\tt ref} refers to reference data and the spectral data are averaged
across the bandpass.  Note that the central 80\% of the spectra are
used for the calculation.

Second, determine antenna temperature (sd.dosigref())

The antenna temperature for each channel is calculated as:

$ T_a(\nu) = T_{sys}$ x 
$\frac{sig(\nu) - ref(\nu)}{ref(\nu)}$

where $sig = \frac{1}{2}(sig_{calon} + sig_{caloff})$, 
      $ref = \frac{1}{2}(sig_{calon} + sig_{caloff}).$


Each calibration routine may be used as:


\small
\begin{verbatim}
  scans=sd.scantable('inputdata',False)         # create a scantable called 'scans'
  calibrated_scans = sd.calps(scans,[scanlist]) # calibrate scantable with position-switched 
                                                # scheme
\end{verbatim}
\normalsize


{\bf Note:} For calps and calnod, the scanlist must be scan pairs in
correct order as these routines only do minimal checking.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Averaging}
\label{subsubsection:sd.asap.averaging}

One can average polarizations in a scantable using the
{\tt sd.scantable.average\_pol} function:
\small
\begin{verbatim}
  averaged_scan = scans.average_pol(mask,weight)

  where:
    Parameters:
        mask:        An optional mask defining the region, where the
                     averaging will be applied. The output will have all
                     specified points masked.
        weight:      Weighting scheme. 'none' (default), 'var' (1/var(spec)
                     weighted), or 'tsys' (1/Tsys**2 weighted)

    Example:

  spave = stave.average_pol(weight='tsys')
\end{verbatim}
\normalsize

One can also average scans over time using {\tt sd.average\_time}:
\small
\begin{verbatim}
  sd.average_time(scantable,mask,scanav,weight,align)

  where:

    Parameters:
        one scan or comma separated  scans
        mask:     an optional mask (only used for 'var' and 'tsys' weighting)
        scanav:   True averages each scan separately.
                  False (default) averages all scans together,
        weight:   Weighting scheme.
                    'none'     (mean no weight)
                    'var'      (1/var(spec) weighted)
                    'tsys'     (1/Tsys**2 weighted)
                    'tint'     (integration time weighted)
                    'tintsys'  (Tint/Tsys**2)
                    'median'   ( median averaging)
        align:    align the spectra in velocity before averaging. It takes
                  the time of the first spectrum in the first scantable
                  as reference time.
    Example:
  
  stave = sd.average_time(scans,weight='tintsys')
\end{verbatim}
\normalsize

Note that alignment of the velocity frame should be done before
averaging if the time spanned by the scantable is 
long enough.  This is done through the {\tt align=True} option in
{\tt sd.average\_time}, or explicitly through the
{\tt sd.scantable.freq\_align} function, e.g.
\small
\begin{verbatim}
CASA <62>: sc = sd.scantable('orions_scan20to23_if0to3.asap',False)
CASA <63>: sc.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <64>: av = sd.average_times(sc)
\end{verbatim}
\normalsize

The time averaging can also be applied to multiple scantables.  This
might have been taken on different days, for example.  The
{\tt sd.average\_time} function takes multiple scantables as input.
However, if taken at significantly different times (different days for
example) then {\tt sd.scantable.freq\_align} must be used to align
the velocity scales to the same time, e.g.
\small
\begin{verbatim}
CASA <65>: sc1 = sd.scantable('orions_scan21_if0to3.asap',False)
CASA <66>: sc2 = sd.scantable('orions_scan23_if0to3.asap',False)
CASA <67>: sc1.freq_align()
Aligned at reference Epoch 2006/01/19/01:49:23 (UTC) in frame LSRK
CASA <68>: sc2.freq_align(reftime='2006/01/19/01:49:23')
Aligned at reference Epoch 2006/01/19/01:54:46 (UTC) in frame LSRK
CASA <69>: scav = sd.average_times(sc1,sc2)
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Spectral Smoothing}
\label{subsection:sd.asap.smoothing}

Smoothing on data can be done as follows:

\small
\begin{verbatim}
  scantable.smooth(kernel,    # type of smoothing: 'hanning' (default), 'gaussian', 'boxcar'
          width,              # width in pixls (ignored for hanning); FWHM for gaussian.
          insitu)             # if False (default), do smoothing in-situ; otherwise, 
                              # make new scantable

  Example:
  # spave is an averaged spectrum
  spave.smooth('boxcar',5)    # do a 5 pixel boxcar smooth on the spectrum
  sd.plotter.plot(spave)      # should see smoothed spectrum
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Baseline Fitting}
\label{subsection:sd.asap.BLfitting}

The function {\tt sd.scantable.poly\_baseline} carries out a
baseline fit, given an mask of channels (if desired):
\small
\begin{verbatim}
  msk=scans.create_mask([100,400],[600,900])
  scans.poly_baseline(msk,order=1)
\end{verbatim}
\normalsize
This will fit a first order polynomial to the selected channels and
subtract this polynomial from the full spectrum.

The {\tt auto\_poly\_baseline} function can be used to automatically
baseline your data without having to specify channel ranges for the
line free data. It automatically figures out the line-free emission
and fits a polynomial baseline to that data. The user can use masks to
fix the range of channels or velocity range for the fit as well as
mark the band edge as invalid:


\small
\begin{verbatim}
  scans.auto_poly_baseline(mask,edge,order,threshold,chan_avg_limit,plot,insitu):

    Parameters:
        mask:       an optional mask retreived from scantable
        edge:       an optional number of channel to drop at
                    the edge of spectrum. If only one value is
                    specified, the same number will be dropped from
                    both sides of the spectrum. Default is to keep
                    all channels. Nested tuples represent individual
                    edge selection for different IFs (a number of spectral
                    channels can be different)
        order:      the order of the polynomial (default is 0)
        threshold:  the threshold used by line finder. It is better to
                    keep it large as only strong lines affect the
                    baseline solution.
        chan_avg_limit:
                    a maximum number of consequtive spectral channels to
                    average during the search of weak and broad lines.
                    The default is no averaging (and no search for weak
                    lines). If such lines can affect the fitted baseline
                    (e.g. a high order polynomial is fitted), increase this
                    parameter (usually values up to 8 are reasonable). Most
                    users of this method should find the default value
                    sufficient.
        plot:       plot the fit and the residual. In this each
                    indivual fit has to be approved, by typing 'y'
                    or 'n'
        insitu:     if False a new scantable is returned.
                    Otherwise, the scaling is done in-situ
                    The default is taken from .asaprc (False)

    Example:
  scans.auto_poly_baseline(order=2,threshold=5)
\end{verbatim}
\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Line Fitting}
\label{subsection:sd.asap.LINEfitting}

Multi-component Gaussian fitting is available. This is done by
creating a fitting object, specifying fit parameters and finally
fitting the data. Fitting can be done on a {\tt scantable} selection
or an entire {\tt scantable} using the {\tt auto\_fit} function.

\small
\begin{verbatim}
  #spave is an averaged spectrum
  f=sd.fitter()                           # create fitter object
  msk=spave.create_mask([3928,4255])      # create mask region around line
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_scan(spave,msk)                   # set the scantable and region
                                          # 
                                          # Automatically guess start values
  f.fit()                                 # fit 
  f.plot(residual=True)                   # plot residual
  f.get_parameters()                      # retrieve fit parameters
  #   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
  #      area = 59.473 K channel
  f.store_fit('orions_hc3n_fit.txt')      # store fit
                                          #
                                          # To specify initial guess:
  f.set_function(gauss=1)                 # set a single gaussian component
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
                                          #   (peak,center,fwhm)
                                          #
                                          # For multiple components set
                                          # initial guesses for each, e.g.
  f.set_function(gauss=2)                 # set two gaussian components
  f.set_gauss_parameters(0.4,4100,200\    # set initial guesses for Gaussian
        ,component=0)                     #   for first component (0)
  f.set_gauss_parameters(0.1,4200,100\    # set initial guesses for Gaussian
        ,component=1)                     #   for second component (1)

\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Plotting}
\label{subsection:sd.asap.plotting}

The ASAP plotter uses the same Python matplotlib library as in CASA
(for x-y plots). It is accessed via the: 

\small
\begin{verbatim}
   sd.plotter<TAB>        # see all functions (omitted here)
  sd.plotter.plot(scans) # the workhorse function
  sd.plotter.set<TAB>
  sd.plotter.set_abcissa     sd.plotter.set_legend      sd.plotter.set_range
  sd.plotter.set_colors      sd.plotter.set_linestyles  sd.plotter.set_selection
  sd.plotter.set_colours     sd.plotter.set_mask        sd.plotter.set_stacking
  sd.plotter.set_font        sd.plotter.set_mode        sd.plotter.set_title
  sd.plotter.set_histogram   sd.plotter.set_ordinate    
  sd.plotter.set_layout      sd.plotter.set_panelling   
\end{verbatim}
\normalsize


Spectra can be plotted at any time, and it will attempt to do the
correct layout depending on whether it is a set of scans or a single
scan. 

The details of the plotter display (matplotlib) are detailed in the
earlier section. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Spectral Analysis Use Case With ASAP Toolkit}
\label{subsection:sd.asap.usecase}

Below is a script that illustrates how to reduce single dish data
using ASAP within CASA.  First a summary of the dataset is given and
then the script.

\small
\begin{verbatim}
#           MeasurementSet Name:  /home/rohir3/jmcmulli/SD/OrionS_rawACSmod      MS Version 2
#
# Project: AGBT06A_018_01
# Observation: GBT(1 antennas)
#
#Data records: 256       Total integration time = 1523.13 seconds
#   Observed from   01:45:58   to   02:11:21
#
#Fields: 4
#  ID   Name          Right Ascension  Declination   Epoch
#  0    OrionS        05:15:13.45      -05.24.08.20  J2000
#  1    OrionS        05:35:13.45      -05.24.08.20  J2000
#  2    OrionS        05:15:13.45      -05.24.08.20  J2000
#  3    OrionS        05:35:13.45      -05.24.08.20  J2000
#
#Spectral Windows:  (8 unique spectral windows and 1 unique polarization setups)
#  SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#  0        8192 LSRK  45464.3506  6.10423298  50005.8766  45489.3536  RR  LL HC3N
#  1        8192 LSRK  45275.7825  6.10423298  50005.8766  45300.7854  RR  LL HN15CO
#  2        8192 LSRK  44049.9264  6.10423298  50005.8766  44074.9293  RR  LL CH3OH
#  3        8192 LSRK  44141.2121  6.10423298  50005.8766  44166.2151  RR  LL HCCC15N
#  12       8192 LSRK  43937.1232  6.10423356  50005.8813  43962.1261  RR  LL HNCO
#  13       8192 LSRK  42620.4173  6.10423356  50005.8813  42645.4203  RR  LL H15NCO
#  14       8192 LSRK  41569.9768  6.10423356  50005.8813  41594.9797  RR  LL HNC18O
#  15       8192 LSRK  43397.8198  6.10423356  50005.8813  43422.8227  RR  LL SiO

# Scans: 21-24  Setup 1 HC3N et al
# Scans: 25-28  Setup 2 SiO et al

casapath=os.environ['AIPSPATH']

#ASAP script                            # COMMENTS                                      
#-------------------------------------- ----------------------------------------------- 
import asap as sd                       #import ASAP package into CASA                  
                                        #Orion-S (SiO line reduction only)
                                        #Notes:
                                        #scan numbers (zero-based) as compared to GBTIDL

                                        #changes made to get to OrionS_rawACSmod
                                        #modifications to label sig/ref positions
os.environ['AIPSPATH']=casapath         #set this environment variable back - ASAP changes it


s=sd.scantable('OrionS_rawACSmod',False)#load the data without averaging                
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scantable}{5}
\caption{\label{fig:scantable} Multi-panel display of the
  scantable. There are two plots per scan indicating the \_psr
  (reference position data) and the \_ps (source data).} 
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
s.summary()                             #summary info                                   
s.set_fluxunit('K')                     # make 'K' default unit
scal=sd.calps(s,[20,21,22,23])          # Calibrate HC3N scans                          
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{scal}{5}
\caption{\label{fig:scal} Two panel plot of the calibrated
  spectra. The GBT data has a separate scan for the SOURCE and
  REFERENCE positions so scans 20,21,22 and 23 result in these two
  spectra.} 
\hrulefill
\end{figure}

\small
\begin{verbatim}
scal.recalc_azel()                      # recalculate az/el to                          
scal.opacity(0.09)                      # do opacity correction                         
sel=sd.selector()                       # Prepare a selection
sel.set_ifs(0)                          # select HC3N IF
scal.set_selection(sel)                 # get this IF
stave=sd.average_time(scal,weight='tintsys')    # average in time
spave=stave.average_pol(weight='tsys')  # average polarizations;Tsys-weighted (1/Tsys**2) average
sd.plotter.plot(spave)                  # plot

spave.smooth('boxcar',5)                # boxcar 5                                      
spave.auto_poly_baseline(order=2)       # baseline fit order=2                          
sd.plotter.plot(spave)                  # plot                                          

spave.set_unit('GHz')                                                                   
sd.plotter.plot(spave)
sd.plotter.set_histogram(hist=True)       # draw spectrum using histogram                 
sd.plotter.axhline(color='r',linewidth=2) # zline                                       
sd.plotter.save('orions_hc3n_reduced.eps')# save postscript spectrum                    
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{spave}{5}
\caption{\label{fig:spave} Calibrated spectrum with a line at zero (using histograms).}
\hrulefill
\end{figure}
 
\small
\begin{verbatim}
spave.set_unit('channel')                                                               
rmsmask=spave.create_mask([5000,7000])  # get rms of line free regions                  
rms=spave.stats(stat='rms',mask=rmsmask)#  rms
                                        #---------------------------------------------- 
                                        #Scan[0] (OrionS_ps) Time[2006/01/19/01:52:05]: 
                                        # IF[0] = 0.048
                                        #----------------------------------------------
                                        # LINE
linemask=spave.create_mask([3900,4200])
max=spave.stats('max',linemask)         #  IF[0] = 0.918
sum=spave.stats('sum',linemask)         #  IF[0] = 64.994
median=spave.stats('median',linemask)   #  IF[0] = 0.091
mean=spave.stats('mean',linemask)       #  IF[0] = 0.210
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                        # Fitting
spave.set_unit('channel')               # set units to channel                          
sd.plotter.plot(spave)                  # plot spectrum
f=sd.fitter()
msk=spave.create_mask([3928,4255])      # create region around line                     
f.set_function(gauss=1)                 # set a single gaussian component               
f.set_scan(spave,msk)                   # set the data and region for the fitter        
f.fit()                                 # fit                                           
f.plot(residual=True)                   # plot residual
\end{verbatim}
\normalsize

% \begin{figure}[h!]
% \pngname{gaussfit}{4}
% \caption{\label{fig:gaussfit} Plot of fit and residual.}
% \hrulefill
% \end{figure}

\small
\begin{verbatim}
f.get_parameters()                      # retrieve fit parameters
#   0: peak = 0.786 K , centre = 4091.236 channel, FWHM = 70.586 channel
#      area = 59.473 K channel
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                                                                        
                                                                                        

f.store_fit('orions_hc3n_fit.txt')      # store fit                                     

# Save the spectrum
spave.save('orions_hc3n_reduced','ASCII',True)  # save the spectrum                     
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Single Dish Imaging}
\label{section:sd.imaging}

Single dish imaging is supported within CASA using standard
tasks and tools. The data must be in the Measurement Set format. Once
there, you can use the {\tt sdgrid} task or the {\tt im} (imager) tool
to create images:

Tool example:

\small
\begin{verbatim}
  scans.save('outputms','MS2')                    # Save your data from ASAP into an MS

  im.open('outputms')                             # open the data set
  im.selectvis(nchan=901,start=30,step=1,         # choose a subset of the dataa   
     spwid=0,field=0)                             # (just the key emission channels) 
  dir='J2000 17:18:29 +59.31.23'                  # set map center                
  im.defineimage(nx=150,cellx='1.5arcmin',        # define image parameters
     phasecenter=dir,mode='channel',start=30,     # (note it assumes symmetry if ny,celly 
     nchan=901,step=1)                            #  aren't specified)
                                                                       
  im.setoptions(ftmachine='sd',cache=1000000000)  # choose SD gridding                
  im.setsdoptions(convsupport=4)                  # use this many pixels to support the 
                                                  # gridding function used
                                                  # (default=prolate spheroidal wave function)
  im.makeimage(type='singledish',                 # make the image
     image='FLS3a_HI.image') 
\end{verbatim}
\normalsize

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Single Dish Imaging Use Case With ASAP Toolkit}
\label{subsection:sd.imaging.usecase}

Again, the data summary and then the script is given below. 

\small
\begin{verbatim}
# Project: AGBT02A_007_01
# Observation: GBT(1 antennas)
# 
#   Telescope Observation Date    Observer       Project
#   GBT       [                   4.57539e+09, 4.5754e+09]Lockman        AGBT02A_007_01
#   GBT       [                   4.57574e+09, 4.57575e+09]Lockman        AGBT02A_007_02
#   GBT       [                   4.5831e+09, 4.58313e+09]Lockman        AGBT02A_031_12
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Data records: 76860       Total integration time = 7.74277e+06 seconds
#    Observed from   22:05:41   to   12:51:56
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Fields: 2
#   ID   Name          Right Ascension  Declination   Epoch
#   0    FLS3a         17:18:00.00      +59.30.00.00  J2000
#   1    FLS3b         17:18:00.00      +59.30.00.00  J2000
# 
# Thu Feb 1 23:15:15 2007    NORMAL ms::summary:
# Spectral Windows:  (2 unique spectral windows and 1 unique polarization setups)
#   SpwID  #Chans Frame Ch1(MHz)    Resoln(kHz) TotBW(kHz)  Ref(MHz)    Corrs
#   0        1024 LSRK  1421.89269  2.44140625  2500        1420.64269  XX  YY
#   1        1024 LSRK  1419.39269  2.44140625  2500        1418.14269  XX  YY


# FLS3 data calibration
# this is calibration part of FLS3 data
#
casapath=os.environ['AIPSPATH']
import asap as sd
os.environ['AIPSPATH']=casapath

print '--Import--'

s=sd.scantable('FLS3_all_newcal_SP',false)         # read in MeasurementSet

print '--Split--'

# splitting the data for each field
s0=s.get_scan('FLS3a*')                            # split the data for the field of interest
s0.save('FLS3a_HI.asap')                           # save this scantable to disk (asap format)
del s0                                             # free up memory from scantable

print '--Calibrate--'
s=sd.scantable('FLS3a_HI.asap')                    # read in scantable from disk (FLS3a)
s.set_fluxunit('K')                                # set the brightness units to Kelvin
scanns = s.getscannos()                            # get a list of scan numbers
sn=list(scanns)                                    # convert it to a list
print "No. scans to be processed:", len(scanns)

res=sd.calfs(s,sn)                                 # calibrate all scans listed using frequency 
                                                   # switched calibration method

print '--Save calibrated data--'
res.save('FLS3a_calfs', 'MS2')                     # Save the dataset as a MeasurementSet

print '--Image data--'
                                                                
im.open('FLS3a_calfs')                             # open the data set
im.selectvis(nchan=901,start=30,step=1,            # choose a subset of the dataa   
spwid=0,field=0)                                   # (just the key emission channels)                 
dir='J2000 17:18:29 +59.31.23'                     # set map center                
im.defineimage(nx=150,cellx='1.5arcmin',           # define image parameters
phasecenter=dir,mode='channel',start=30,           # (note it assumes symmetry if ny,celly 
nchan=901,step=1)                                  #  aren't specified)
                                                                       
im.setoptions(ftmachine='sd',cache=1000000000)     # choose SD gridding                
im.setsdoptions(convsupport=4)                     # use this many pixels to support the 
                                                   # gridding function used       
                                                   # (default=prolate spheroidal wave function)  
im.makeimage(type='singledish',image='FLS3a_HI.image') # make the image
\end{verbatim}
\normalsize

\begin{figure}[h!]
\pngname{HI_cube}{7}
\caption{\label{fig:HI_cube} FLS3a HI emission. The display
  illustrates the visualization of the data cube (left) and the
  profile display of the cube at the cursor location (right); the
  Tools menu of the Viewer Display Panel has a Spectral Profile button
  which brings up this display. By default, it grabs the left-mouse
  button. Pressing down the button and moving in the display will show
  the profile variations. }
\hrulefill
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Known Issues, Problems, Deficiencies and Features}
\label{section:sd.issues}

The Single-Dish calibration and analysis package within CASA is still
very much under development.  Not surprisingly,
there are a number of issues with ASAP and the SDtasks that are known and
are under repair.  Some of these are non-obvious "features" of the way
ASAP or {\tt sd} is implemented, or limitations of the current Python
tasking environment.  Some are functions that have yet to be
implemented.  These currently include: 

\begin{enumerate}

\item {\tt sd.plotter}

  Currently you can get hardcopy only after making a viewed plot.
  Ideally, ASAP should allow you to choose the device for plotting
  when you set up the plotter.

  Multi-panel plotting is poor.  Currently you can only add things
  (like lines, text, etc.) to the first panel.  Also,
  {\tt sd.plotter.set\_range()} sets the same range for multiple panels,
  while we would like it to be able to set the range for each independently,
  including the default ranges.

  The appearance of the plots need to be made a lot better.  In
  principle matplotlib can make "publication quality" figures, but in
  practice you have to do alot of work to make it do that, and our plots 
  are not good.

  The sd.plotter object remembers things throughout the session
  and thus can easily get confused.  For example you have to
  reset the range {\tt sd.plotter.set\_range()} if you have ever set it
  manually.  This is not always the expected behavior but is a consequence
  of having {\tt sd.plotter} be its own object that you feed data and
  commands to.

  Eventually we would like the capability to interactively set things
  using the plots, like select frequency ranges, identify lines,
  start fitting.

\item {\tt sd.selector}

  The selector object only allows one selection of each type.  It would be 
  nice to be able to make a union of selections (without resorting to query)
  for the {\tt set\_name} - note that the others like scans and IFs work off
  lists which is fine.  Should make {\tt set\_name} work off lists of names.

\item {\tt sd.scantable}

  There is no useful inline help on the scantable constructor
  when you do {\tt help sd.scantable}, nor in {help sd}.

  The inline help for scantable.summary claims that there is
  a verbose parameter, but there is not.  The scantable.verbosesummary
  asaprc parameter (e.g. in {\tt sd.rcParams}) does nothing.

  GBT data has incorrect fluxunit ({\tt 'Jy'}, should be {\tt 'K'}), 
  freqframe ({\tt 'LSRK'}, is really {\tt 'TOPO'}) and reference
  frequency (set to that of the first IF only).

  You cannot set the rest frequencies for GBT data.
  THIS IS THE MOST SERIOUS BUG RIGHT NOW.

  The {\tt sd.scantable.freq\_align} does not yet work correctly.

  Need to add to scantable.stats:
      {\tt 'maxord', 'minord'} - the ordinate (channel, vel, freq) 
      of the max/min
  
\item {\tt sd} general issues

  There should be a {\tt sdhelp} equivalent of {\tt toolhelp}
  and {\tt tasklist} for the sd tools and tasks.

  The current output of ASAP is verbose, and is controlled by
  setting {\tt sd.rcParams['verbose']=False} (or {\tt True}).
  At the least we should make some of the output less cryptic.

  Strip off leading and trailing whitespace on string parameters.

\item SDtasks general issues

  The SDtasks work off of files saved onto disk in one of the 
  scantable supported formats.  It might be useful to be able to
  work off of scantables in memory (passing the objects) but this
  would require changes to the tasking system.  Note that this
  behavior is consistent throughout the casapy tasks.

  Need interactive region selection, baseline fitting, etc.

\item {\tt sdcal}

  Can crash if {\tt timeaverage=True} and/or {\tt polaverage=True}
  and you give a
  list of scans that contain a combination of IFs.  We need to make
  the tools smarter about this, but in the meantime you should restrict
  your scanlist and iflist to scans with the same set of IFs.

\item {\tt sdfit}

  Handles multiple IFs poorly (a general problem currently in the package).

  No way to input guesses.

\item {\tt sdplot}

  Only handles included JPL line catalog.

  Also, see {\tt sd.plotter} issues above.

\item {\tt sdstat}

  Cannot return the location (channel, frequency, or velocity) of the
  maximum or minimum.

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
